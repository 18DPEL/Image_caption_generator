{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":7084977,"datasetId":4082028,"databundleVersionId":7172707},{"sourceType":"datasetVersion","sourceId":7080856,"datasetId":4079014,"databundleVersionId":7168536},{"sourceType":"datasetVersion","sourceId":7638050,"datasetId":2455601,"databundleVersionId":7734448}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\n---\n\n","metadata":{"id":"dT9AQwdf8sJK"}},{"cell_type":"markdown","source":"# **Get the code and models**","metadata":{"id":"yJ5taGmPcWV-"}},{"cell_type":"code","source":"#@title <h1>Install Wav2Lip</h1>\n#@markdown * Install dependencies\n#@markdown * Download models\n!rm -rf sample_data\n!mkdir sample_data","metadata":{"execution":{"iopub.status.busy":"2024-02-29T22:47:05.820455Z","iopub.execute_input":"2024-02-29T22:47:05.820904Z","iopub.status.idle":"2024-02-29T22:47:07.718564Z","shell.execute_reply.started":"2024-02-29T22:47:05.820850Z","shell.execute_reply":"2024-02-29T22:47:07.717166Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/zabique/Wav2Lip\n\n#download the pretrained model\n!wget 'https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA' -O 'Wav2Lip/checkpoints/wav2lip_gan.pth'\n!wget 'https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/Eb3LEzbfuKlJiR600lQWRxgBIY27JZg80f7V9jtMfbNDaQ?e=TBFBVW' -O 'Wav2Lip/checkpoints/wav2lip.pth'\n!pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl\n\n# !pip uninstall tensorflow tensorflow-gpu\n!cd Wav2Lip && pip install -r requirements.txt\n\n#download pretrained model for face detection\n!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\"\n\n!pip install -q youtube-dl\n!pip install ffmpeg-python\n\n\n#this code for recording audio\n\"\"\"\nTo write this piece of code I took inspiration/code from a lot of places.\nIt was late night, so I'm not sure how much I created or just copied o.O\nHere are some of the possible references:\nhttps://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\nhttps://stackoverflow.com/a/18650249\nhttps://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\nhttps://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\nhttps://stackoverflow.com/a/49019356\n\"\"\"\nfrom IPython.display import HTML, Audio\n# from google.colab.output import eval_js\nfrom base64 import b64decode\nimport numpy as np\nfrom scipy.io.wavfile import read as wav_read\nimport io\nimport ffmpeg\n\nAUDIO_HTML = \"\"\"\n<script>\nvar my_div = document.createElement(\"DIV\");\nvar my_p = document.createElement(\"P\");\nvar my_btn = document.createElement(\"BUTTON\");\nvar t = document.createTextNode(\"Press to start recording\");\n\nmy_btn.appendChild(t);\n//my_p.appendChild(my_btn);\nmy_div.appendChild(my_btn);\ndocument.body.appendChild(my_div);\n\nvar base64data = 0;\nvar reader;\nvar recorder, gumStream;\nvar recordButton = my_btn;\n\nvar handleSuccess = function(stream) {\n  gumStream = stream;\n  var options = {\n    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n    mimeType : 'audio/webm;codecs=opus'\n    //mimeType : 'audio/webm;codecs=pcm'\n  };            \n  //recorder = new MediaRecorder(stream, options);\n  recorder = new MediaRecorder(stream);\n  recorder.ondataavailable = function(e) {            \n    var url = URL.createObjectURL(e.data);\n    var preview = document.createElement('audio');\n    preview.controls = true;\n    preview.src = url;\n    document.body.appendChild(preview);\n\n    reader = new FileReader();\n    reader.readAsDataURL(e.data); \n    reader.onloadend = function() {\n      base64data = reader.result;\n      //console.log(\"Inside FileReader:\" + base64data);\n    }\n  };\n  recorder.start();\n  };\n\nrecordButton.innerText = \"Recording... press to stop\";\n\nnavigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n\n\nfunction toggleRecording() {\n  if (recorder && recorder.state == \"recording\") {\n      recorder.stop();\n      gumStream.getAudioTracks()[0].stop();\n      recordButton.innerText = \"Saving the recording... pls wait!\"\n  }\n}\n\n// https://stackoverflow.com/a/951057\nfunction sleep(ms) {\n  return new Promise(resolve => setTimeout(resolve, ms));\n}\n\nvar data = new Promise(resolve=>{\n//recordButton.addEventListener(\"click\", toggleRecording);\nrecordButton.onclick = ()=>{\ntoggleRecording()\n\nsleep(2000).then(() => {\n  // wait 2000ms for the data to be available...\n  // ideally this should use something like await...\n  //console.log(\"Inside data:\" + base64data)\n  resolve(base64data.toString())\n\n});\n\n}\n});\n      \n</script>\n\"\"\"\n\n# %cd /\n# from ghc.l_ghc_cf import l_ghc_cf\n# %cd content\n\ndef get_audio():\n  display(HTML(AUDIO_HTML))\n  data = eval_js(\"data\")\n  binary = b64decode(data.split(',')[1])\n  \n  process = (ffmpeg\n    .input('pipe:0')\n    .output('pipe:1', format='wav')\n    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n  )\n  output, err = process.communicate(input=binary)\n  \n  riff_chunk_size = len(output) - 8\n  # Break up the chunk size into four bytes, held in b.\n  q = riff_chunk_size\n  b = []\n  for i in range(4):\n      q, r = divmod(q, 256)\n      b.append(r)\n\n  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n  riff = output[:4] + bytes(b) + output[8:]\n\n  sr, audio = wav_read(io.BytesIO(riff))\n\n  return audio, sr\n\n\nfrom IPython.display import HTML\nfrom base64 import b64encode\ndef showVideo(path):\n  mp4 = open(str(path),'rb').read()\n  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n  return HTML(\"\"\"\n  <video width=700 controls>\n        <source src=\"%s\" type=\"video/mp4\">\n  </video>\n  \"\"\" % data_url)\n\nfrom IPython.display import clear_output \n# clear_output()\nprint(\"\\nDone\")","metadata":{"execution":{"iopub.status.busy":"2023-11-29T19:07:41.943156Z","iopub.execute_input":"2023-11-29T19:07:41.943790Z","iopub.status.idle":"2023-11-29T19:08:45.278101Z","shell.execute_reply.started":"2023-11-29T19:07:41.943756Z","shell.execute_reply":"2023-11-29T19:08:45.276851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n---\n\n","metadata":{"id":"vzokJMO19IyY"}},{"cell_type":"markdown","source":"# **Quick guide**\n1. Create video file input_video.mp4\n2. Create audio file input_audio.wav\n3. Both files have to be exact same length\n4. Target face in the input_video.mp4, must be in ALL videoframes (So no black or blurry frames etc)\n","metadata":{"id":"RgjaWJFs8B38"}},{"cell_type":"markdown","source":"# **Now lets try!**","metadata":{"id":"qdIQfY2Kswcb"}},{"cell_type":"code","source":"#@title 1.Upload input_video.mp4 & input_audio.wav files\n# %cd sample_data/\n# from google.colab import files\n# uploaded = files.upload()\n# %cd ..","metadata":{"id":"vsphzJawLF-f","outputId":"061fa402-95a7-43c9-9e37-b4d406da7174","execution":{"iopub.status.busy":"2023-11-29T19:08:45.280061Z","iopub.execute_input":"2023-11-29T19:08:45.280383Z","iopub.status.idle":"2023-11-29T19:08:45.284993Z","shell.execute_reply.started":"2023-11-29T19:08:45.280354Z","shell.execute_reply":"2023-11-29T19:08:45.284039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install pydub\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T19:10:16.748394Z","iopub.execute_input":"2023-11-29T19:10:16.748794Z","iopub.status.idle":"2023-11-29T19:10:28.210317Z","shell.execute_reply.started":"2023-11-29T19:10:16.748764Z","shell.execute_reply":"2023-11-29T19:10:28.208932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pydub import AudioSegment\n\ndef convert_mp3_to_wav(mp3_file, wav_file):\n    # Load the MP3 file\n    audio = AudioSegment.from_mp3(\"/kaggle/input/video-dataset/audio.mp3\")\n\n    # Export as WAV\n    audio.export(wav_file, format=\"wav\")\n\n# Example usage\nconvert_mp3_to_wav(\"input.mp3\", \"output.wav\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T19:10:28.213040Z","iopub.execute_input":"2023-11-29T19:10:28.214403Z","iopub.status.idle":"2023-11-29T19:10:28.479962Z","shell.execute_reply.started":"2023-11-29T19:10:28.214366Z","shell.execute_reply":"2023-11-29T19:10:28.479109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convert_mp3_to_wav(\"input.mp3\", \"/kaggle/working/output.wav\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T19:10:28.481247Z","iopub.execute_input":"2023-11-29T19:10:28.481516Z","iopub.status.idle":"2023-11-29T19:10:28.743489Z","shell.execute_reply.started":"2023-11-29T19:10:28.481491Z","shell.execute_reply":"2023-11-29T19:10:28.742532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title 1a. Record your own voice\n# from IPython.display import Audio \n# from IPython.core.display import display\n\n# record_or_upload = 'record' #@param ['record', 'Upload']\n\n# def displayAudio():\n#   display(Audio('/content/sample_data/input_audio.wav'))\n# if record_or_upload == 'record':\n#   audio, sr = get_audio()\n#   import scipy\n#   scipy.io.wavfile.write('/content/sample_data/input_audio.wav', sr, audio)\n# elif record_or_upload == 'Upload':\n#   from google.colab import files\n#   uploaded = files.upload()\n#   for fn in uploaded.keys():\n#     print('User uploaded file \"{name}\" with length {length} bytes'.format(\n#         name=fn, length=len(uploaded[fn])))\n  \n#   #concider only the first file\n#   audio_file = str(list(uploaded.keys())[0])\n#   !rm -f '/content/sample_data/input_audio.wav'\n#   !ffmpeg -i '$audio_file' '/content/sample_data/input_audio.wav'\n\n#   clear_output()\n#   displayAudio()","metadata":{"id":"qfHxyd58PWsh","outputId":"aa2b16b3-5aa1-4062-f429-9715ff0d26cf","execution":{"iopub.status.busy":"2023-11-29T19:10:28.745296Z","iopub.execute_input":"2023-11-29T19:10:28.745601Z","iopub.status.idle":"2023-11-29T19:10:28.750387Z","shell.execute_reply.started":"2023-11-29T19:10:28.745574Z","shell.execute_reply":"2023-11-29T19:10:28.749489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title 2.Create Wav2Lip video (using wav2lip_gan.pth) GAN\n%cd Wav2Lip\n\n!python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/kaggle/input/wav2lip-dataset/input_video.mp4\" --audio \"/kaggle/input/wav2lip-dataset/input_audio.wav\"\n# !python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/kaggle/input/wav2lip-dataset/MonnaLisa.mp4\" --audio \"/kaggle/input/wav2lip-dataset/MonnaLisa.wav\"\n# !python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/kaggle/input/wav2lip-dataset/girl.mp4\" --audio \"/kaggle/input/wav2lip-dataset/girl.wav\"\n\n# !python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/kaggle/input/wav2lip-dataset/MonnaLisa.mp4\" --audio \"/kaggle/input/wav2lip-dataset/AI.wav\"\n# !python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/kaggle/input/wav2lip-dataset/girl.mp4\" --audio \"/kaggle/input/wav2lip-dataset/AI2.wav\"\n\n# from IPython.display import clear_output \n# clear_output()\n# print(\"\\nDone! now press X\")","metadata":{"id":"jR5utmDMcSZY","outputId":"12f2c636-8d87-4a63-eed1-d6b2efb0b14e","execution":{"iopub.status.busy":"2023-11-29T19:10:28.751725Z","iopub.execute_input":"2023-11-29T19:10:28.752082Z","iopub.status.idle":"2023-11-29T19:10:33.988243Z","shell.execute_reply.started":"2023-11-29T19:10:28.752050Z","shell.execute_reply":"2023-11-29T19:10:33.987063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title 3.Play result video -  50% scaling\nfrom IPython.display import HTML\nfrom base64 import b64encode\nmp4 = open('results/result_voice.mp4','rb').read()\ndata_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\nHTML(f\"\"\"\n<video width=\"50%\" height=\"50%\" controls>\n      <source src=\"{data_url}\" type=\"video/mp4\">\n</video>\"\"\")","metadata":{"id":"WxbzXZvLliiA","outputId":"d91522c9-6d94-489d-bcff-7eb6e6b4d836","execution":{"iopub.status.busy":"2023-11-29T19:07:29.974340Z","iopub.execute_input":"2023-11-29T19:07:29.974746Z","iopub.status.idle":"2023-11-29T19:07:30.485851Z","shell.execute_reply.started":"2023-11-29T19:07:29.974714Z","shell.execute_reply":"2023-11-29T19:07:30.484476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #@title 4.Download Result.mp4 to your computer\n# from google.colab import files\n# files.download('/content/Wav2Lip/results/result_voice.mp4') \n","metadata":{"id":"1kt-krsEbz5j","outputId":"90c74a9a-237c-4a3f-cdcb-85f111f1dcee","execution":{"iopub.status.busy":"2023-11-29T19:07:31.730395Z","iopub.execute_input":"2023-11-29T19:07:31.731144Z","iopub.status.idle":"2023-11-29T19:07:31.735009Z","shell.execute_reply.started":"2023-11-29T19:07:31.731110Z","shell.execute_reply":"2023-11-29T19:07:31.734057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #@title 5. Delete old result files\n# %rm /content/sample_data/*\n# from IPython.display import clear_output \n# clear_output()\n# print(\"\\nDone! now press X\")","metadata":{"id":"fT8njpBCJ7gD","outputId":"d5f7b6e2-ca2f-46ce-8d83-6bb3bbf6672f","execution":{"iopub.status.busy":"2023-11-29T19:07:32.026354Z","iopub.execute_input":"2023-11-29T19:07:32.027093Z","iopub.status.idle":"2023-11-29T19:07:32.030952Z","shell.execute_reply.started":"2023-11-29T19:07:32.027059Z","shell.execute_reply":"2023-11-29T19:07:32.030018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #@title 1-4. Batch processing - Upload -> process -> download -> play result\n# %cd sample_data/\n# %rm input_audio.wav\n# %rm input_video.mp4\n# from google.colab import files\n# uploaded = files.upload()\n# %cd ..\n# !cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\"\n# from google.colab import files\n# files.download('/content/Wav2Lip/results/result_voice.mp4') \n# from IPython.display import HTML\n# from base64 import b64encode\n# mp4 = open('/content/Wav2Lip/results/result_voice.mp4','rb').read()\n# data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n# HTML(f\"\"\"\n# <video width=\"50%\" height=\"50%\" controls>\n#       <source src=\"{data_url}\" type=\"video/mp4\">\n# </video>\"\"\")","metadata":{"id":"2OhT0w2uT4rQ","execution":{"iopub.status.busy":"2023-11-29T08:28:00.422030Z","iopub.execute_input":"2023-11-29T08:28:00.422396Z","iopub.status.idle":"2023-11-29T08:28:00.431600Z","shell.execute_reply.started":"2023-11-29T08:28:00.422356Z","shell.execute_reply":"2023-11-29T08:28:00.430561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Variations to try**\n","metadata":{"id":"d7zgfrQqbKom"}},{"cell_type":"code","source":"# #@title 2.Use resize_factor to reduce the video resolution, as there is a change you might get better results for lower resolution videos. Why? Because the model was trained on low resolution faces.\n# !cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\" --resize_factor 2","metadata":{"id":"xw0xFtZ2bsx8","execution":{"iopub.status.busy":"2023-11-29T08:28:00.433181Z","iopub.execute_input":"2023-11-29T08:28:00.433539Z","iopub.status.idle":"2023-11-29T08:28:00.441858Z","shell.execute_reply.started":"2023-11-29T08:28:00.433507Z","shell.execute_reply":"2023-11-29T08:28:00.440753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #@title 3.Use more padding to include the chin region (u can manually edit pads dimensions viewing and changing the code)\n# !cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\" --pads 0 20 0 0","metadata":{"id":"45XW4SZAzIz5","execution":{"iopub.status.busy":"2023-11-29T08:28:00.443178Z","iopub.execute_input":"2023-11-29T08:28:00.443509Z","iopub.status.idle":"2023-11-29T08:28:00.451909Z","shell.execute_reply.started":"2023-11-29T08:28:00.443477Z","shell.execute_reply":"2023-11-29T08:28:00.450957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #@title 4.Play result video -  50% scaling\n# from IPython.display import HTML\n# from base64 import b64encode\n# mp4 = open('/content/Wav2Lip/results/result_voice.mp4','rb').read()\n# data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n# HTML(f\"\"\"\n# <video width=\"50%\" height=\"50%\" controls>\n#       <source src=\"{data_url}\" type=\"video/mp4\">\n# </video>\"\"\")","metadata":{"id":"X1Z0zRdZR5BZ","execution":{"iopub.status.busy":"2023-11-29T08:28:00.453289Z","iopub.execute_input":"2023-11-29T08:28:00.453657Z","iopub.status.idle":"2023-11-29T08:28:00.470865Z","shell.execute_reply.started":"2023-11-29T08:28:00.453627Z","shell.execute_reply":"2023-11-29T08:28:00.469666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #@title 5.Download Result.mp4 to your computer\n# from google.colab import files\n# files.download('/content/Wav2Lip/results/result_voice.mp4') \n","metadata":{"cellView":"form","id":"gfXFOpAmR_dh","execution":{"iopub.status.busy":"2023-11-29T08:28:00.472462Z","iopub.execute_input":"2023-11-29T08:28:00.472929Z","iopub.status.idle":"2023-11-29T08:28:00.482396Z","shell.execute_reply.started":"2023-11-29T08:28:00.472883Z","shell.execute_reply":"2023-11-29T08:28:00.481158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}